<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <!-- Hi, Jon Here. Please DELETE the two <script> tags below if you use this HTML, otherwise my analytics will track your page -->
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <!--<script async src="https://www.googletagmanager.com/gtag/js?id=UA-7580334-2"></script>-->
  <!--<script>-->
    <!--window.dataLayer = window.dataLayer || [];-->
    <!--function gtag(){dataLayer.push(arguments);}-->
    <!--gtag('js', new Date());-->

    <!--gtag('config', 'UA-7580334-2');-->
  <!--</script>-->

  <title>Weiyu Liu</title>
  
  <meta name="author" content="Weiyu Liu">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" type="image/png" href="images/buzz.png">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Weiyu Liu</name>
              </p>
              <p>
                I am a Postdoctoral Scholar working with <a href="https://jiajunwu.com/">Jiajun Wu</a> in the CogAI group and <a href="https://svl.stanford.edu/">Stanford Vision and Learning Lab (SVL)</a>. I completed my Ph.D. in robotics at Georgia Institute of Technology, where I am advised by <a href="https://www.cc.gatech.edu/~chernova/">Sonia Chernova</a>.
                In 2021 and 2022, I interned at Nvidia Research, working with <a href="https://homes.cs.washington.edu/~fox/">Dieter Fox</a>, <a href="https://robot-learning.cs.utah.edu/thermans">Tucker Hermans</a>, <a href="https://animesh.garg.tech/">Animesh Garg</a>, and <a href="https://cpaxton.github.io/about/">Chris Paxton</a>.
                Prior to joining the Ph.D. program, I received my Bachelor’s degree in Electrical Engineering from Georgia Tech.
              </p>
              <p>
                The goal of my research is to develop robots that can effectively perceive, model, and interact with the real world.
                I am particularly interested in the application where human users can easily command robots to complete long-horizon tasks via simple language commands, such as "make the tea".
                Achieving this requires robust generalization across various dimensions, including objects, environments, actions, and tasks.
                My core insight is that strong generalization can be achieved through a structured representation of world knowledge.
                Rather than constructing this representation from scratch, robots should leverage the rich knowledge embedded in human language, grounding it through interactions with their environments to connect abstract knowledge to their sensorimotor capabilities.
              </p>
              <p>
                My prior research has investigated core components of this structured knowledge representation, methods to extract and refine this knowledge extracted from humans, and algorithms that enable reasoning with this knowledge to support broad generalization.
              </p>
              <p style="text-align:center">
                <a href="mailto:weiyul@stanford.edu">Email</a> &nbsp/&nbsp
                <a href="data/CV-WeiyuLiu.pdf">CV (Nov 2024)</a> &nbsp/&nbsp
                <a href="data/WeiyuLiu-ResearchStatement.pdf">Research Statement (2022)</a> <br>
                <a href="https://scholar.google.com/citations?user=PHi0YEQAAAAJ&hl=en">Google Scholar</a> &nbsp/&nbsp
                <a href="https://github.com/wliu88">Github</a> &nbsp/&nbsp
                <a href="https://twitter.com/Weiyu_Liu_">Twitter</a>
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/WeiyuLiuRobot.jpg"><img style="width:90%;max-width:100%" alt="profile photo" src="images/WeiyuLiuRobot.jpg" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>
        <!--<table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>-->
            <!--<tr>-->
            <!--<td style="padding:20px;width:100%;vertical-align:middle">-->
              <!--<heading>Semantic Reasoning</heading>-->
              <!--<p>-->
                <!--&lt;!&ndash;Robots are increasingly transitioning from specialized, single task machines to general-purpose systems that operate in diverse and dynamic environments.  &ndash;&gt;-->
                <!--&lt;!&ndash;I'm interested in computer vision, machine learning, optimization, and image processing.&ndash;&gt;-->
                <!--&lt;!&ndash;Much of my research is about inferring the physical world (shape, motion, color, light, etc) from images.&ndash;&gt;-->
                <!--&lt;!&ndash;Representative papers are <span class="highlight">highlighted</span>.&ndash;&gt;-->
              <!--</p>-->
            <!--</td>-->
          <!--</tr>-->
        <!--</tbody></table>-->
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

          <tr onmouseout="blade_stop()" onmouseover="blade_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='blade_image'><video  width=100% height=100% muted autoplay loop>
                <source src="images/blade.mp4" type="video/mp4">
                Your browser does not support the video tag.
                </video></div>
                <img src='images/blade.jpg' width="160">
              </div>
              <script type="text/javascript">
                function blade_start() {
                  document.getElementById('blade_image').style.opacity = "1";
                }

                function blade_stop() {
                  document.getElementById('blade_image').style.opacity = "0";
                }
                blade_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://blade-bot.github.io/">
                <papertitle>Learning Compositional Behaviors from Demonstration and Language</papertitle>
              </a>
              <br>
              <br>
              <strong>Weiyu Liu*</strong>,
              <a href="https://neilnie.com/">Neil Nie*</a>,
              <a href="https://ai.stanford.edu/~zharu/">Ruohan Zhang</a>,
              <a href="https://jiayuanm.com/">Jiayuan Mao<sup>†</sup></a>,
              <a href="https://jiajunwu.com/">Jiajun Wu<sup>†</sup></a>
              <br>
              <em>Conference on Robot Learning (CoRL)</em>, 2024
              <br>
              <a href="https://openreview.net/forum?id=fR1rCXjCQX&noteId=fR1rCXjCQX">paper</a> /
              <a href="https://blade-bot.github.io/">website</a> /
              <a href="data/blade.bib">bibtex</a>
            </td>
          </tr>
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/parl.png" alt="planning_abstractions_png" width="160" style="border-style: none">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://parl2024.github.io/">
                <papertitle>Learning Planning Abstractions from Language</papertitle>
              </a>
              <br>
              <br>
              <strong>Weiyu Liu*</strong>,
              <a href="https://jc043.github.io/">Geng Chen*</a>,
              <a href="https://stanford.edu/~joycj/">Joy Hsu</a>,
              <a href="https://jiayuanm.com/">Jiayuan Mao<sup>†</sup></a>,
              <a href="https://jiajunwu.com/">Jiajun Wu<sup>†</sup></a>
              <br>
              <em>International Conference on Learning Representations (ICLR)</em>, 2024
              <br>
              <a href="https://arxiv.org/abs/2405.03864">arxiv</a> /
              <a href="https://parl2024.github.io/">website</a> /
              <a href="data/parl.bib">bibtex</a>
            </td>
          </tr>
          <tr onmouseout="ikea_stop()" onmouseover="ikea_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='ikea_image'><video  width=100% height=100% muted autoplay loop>
                <source src="images/ikea.mp4" type="video/mp4">
                Your browser does not support the video tag.
                </video></div>
                <img src='images/ikea.jpg' width="160">
              </div>
              <script type="text/javascript">
                function ikea_start() {
                  document.getElementById('ikea_image').style.opacity = "1";
                }

                function ikea_stop() {
                  document.getElementById('ikea_image').style.opacity = "0";
                }
                ikea_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://yunongliu1.github.io/ikea-video-manual/">
                <papertitle>IKEA Manuals at Work: 4D Grounding of Assembly Instructions on Internet Videos</papertitle>
              </a>
              <br>
              <br>
              <a href="https://yunongliu.com/">Yunong Liu</a>,
              <a href="https://ceyzaguirre4.github.io/">Cristobal Eyzaguirre</a>,
              <a href="https://www.niebles.net/">Juan Carlos Niebles</a>,
              <a href="https://scholar.google.com/citations?user=iNT6NOAAAAAJ&hl=en">Vineeth Ravi</a>,
              <a href="https://sites.google.com/site/saumitramishrac4dm">Saumitra Mishra</a>,
              <strong>Weiyu Liu<sup>†</sup></strong>,
              <a href="https://jiajunwu.com/">Jiajun Wu<sup>†</sup></a>
              <br>
              <em>Neural Information Processing Systems (NeurIPS) Datasets and Benchmarks Track</em>, 2024
              <br>
              <a href="https://openreview.net/forum?id=EXwf5iE98P#discussion">paper</a> /
              <a href="https://yunongliu1.github.io/ikea-video-manual/">website</a> /
              <a href="https://github.com/yunongLiu1/IKEA-Manuals-at-Work">code and data</a> /
              <a href="data/ikea.bib">bibtex</a>
            </td>
          </tr>
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/larc.png" alt="3d_visual_grounding_png" width="160" style="border-style: none">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://chunfeng3364.github.io/projects/larc_website/project_page.html">
                <papertitle>Naturally Supervised 3D Visual Grounding with Language-Regularized Concept Learners</papertitle>
              </a>
              <br>
              <br>
              <a href="https://chunfeng3364.github.io/">Chun Feng*</a>,
              <a href="https://stanford.edu/~joycj/">Joy Hsu*</a>,
              <strong>Weiyu Liu</strong>,
              <a href="https://jiajunwu.com/">Jiajun Wu</a>
              <br>
              <em>IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</em>, 2024
              <br>
              <a href="https://arxiv.org/abs/2404.19696">paper</a> /
              <a href="https://chunfeng3364.github.io/projects/larc_website/project_page.html">website</a> /
              <a href="https://github.com/chunfeng3364/LARC">code</a>
              <a href="data/larc.bib">bibtex</a>
            </td>
          </tr>
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/eai.png" alt="embodied_agent_interface_png" width="160" style="border-style: none">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://embodied-agent-interface.github.io/">
                <papertitle>Embodied Agent Interface: Benchmarking LLMs for Embodied Decision Making</papertitle>
              </a>
              <br>
              <br>
              <a href="https://limanling.github.io/">Manling Li*</a>,
              <a href="https://shiyu-zhao.netlify.app/">Shiyu Zhao*</a>,
              <a href="https://qinengwang-aiden.github.io/">Qineng Wang*</a>,
              <a href="https://jameskrw.github.io/">Kangrui Wang*</a>,
              <a href="https://bryanzhou008.github.io/">Yu Zhou*</a>,
              <a href="https://www.linkedin.com/in/sanjana-srivastava5/">Sanjana Srivastava</a>,
              <a href="https://www.cemgokmen.com/">Cem Gokmen</a>,
              <a href="https://profiles.stanford.edu/tonyhlee">Tony Lee</a>,
              <a href="https://www.cs.columbia.edu/~lierranli/">Li Erran Li</a>,
              <a href="https://ai.stanford.edu/~zharu/">Ruohan Zhang</a>,
              <strong>Weiyu Liu</strong>,
              <br>
              <a href="https://cs.stanford.edu/~pliang/">Percy Liang</a>,
              <a href="https://profiles.stanford.edu/fei-fei-li">Li Fei-Fei</a>,
              <a href="https://jiayuanm.com/">Jiayuan Mao</a>,
              <a href="https://jiajunwu.com/">Jiajun Wu</a>
              <br>
              <em>Neural Information Processing Systems (NeurIPS) Datasets and Benchmarks Track</em>, 2024
              <br>
              <a href="https://arxiv.org/abs/2410.07166">paper</a> /
              <a href="https://embodied-agent-interface.github.io/">website</a> /
              <a href="https://github.com/embodied-agent-interface/embodied-agent-interface">code</a> /
              <a href="data/eai">bibtex</a>
            </td>
          </tr>
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/marple.png" alt="marple_png" width="160" style="border-style: none">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://marple-benchmark.github.io/">
                <papertitle>MARPLE: A Benchmark for Long-Horizon Inference</papertitle>
              </a>
              <br>
              <br>
              <a href="https://www.linkedin.com/in/emily-jin-020/">Emily Jin</a>,
              <a href="https://www.linkedin.com/in/zhuoyi-huang/">Zhuoyi Huang</a>,
              <a href="https://janphilippfranken.github.io/">Jan-Philipp Fränken</a>,
              <strong>Weiyu Liu</strong>,
              <a href="https://www.hannahcha.com/about">Hannah Cha</a>,
              <a href="https://sarahawu.github.io/">Sarah A. Wu</a>,
              <a href="https://www.erikbrockbank.com/">Erik Brockbank</a>,
              <a href="https://ai.stanford.edu/~zharu/">Ruohan Zhang</a>,
              <a href="https://jiajunwu.com/">Jiajun Wu</a>,
              <a href="https://cicl.stanford.edu/member/tobias_gerstenberg/">Tobias Gerstenberg</a>
              <br>
              <em>Neural Information Processing Systems (NeurIPS) Datasets and Benchmarks Track</em>, 2024
              <br>
              <a href="https://arxiv.org/abs/2410.01926">arxiv</a> /
              <a href="https://marple-benchmark.github.io/">website</a> /
              <a href="https://github.com/marple-benchmark/marple">code and data</a> /
              <a href="data/marple.bib">bibtex</a>
            </td>
          </tr>


          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/survey.jpg" alt="survey_png" width="160" style="border-style: none">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://www.sciencedirect.com/science/article/abs/pii/S092188902200183X">
                <papertitle>A Survey of Semantic Reasoning Frameworks for Robotic Systems</papertitle>
              </a>
              <br>
              <br>
              <strong>Weiyu Liu<sup>1</sup></strong>,
              <a href="http://www.prism.gatech.edu/~adaruna3/">Angel Daruna<sup>1</sup></a>,
              <a href="https://maithili.github.io/">Maithili Patel<sup>2</sup></a>,
              <a href="https://kartikvrama.github.io/">Kartik Ramachandruni<sup>2</sup></a>,
              <a href="https://www.cc.gatech.edu/~chernova/">Sonia Chernova</a>
              <br>
              <em>Robotics and Autonomous Systems</em>, 2023
              <br>
              <a href="https://www.sciencedirect.com/science/article/abs/pii/S092188902200183X">paper</a> /
              <a href="data/LiuSurvey2023.bib">bibtex</a>
            </td>
          </tr>

          <tr onmouseout="cpm_stop()" onmouseover="cpm_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='cpm_image'><video  width=100% height=100% muted autoplay loop>
                <source src="images/cpm.mp4" type="video/mp4">
                Your browser does not support the video tag.
                </video></div>
                <img src='images/cpm.jpg' width="160">
              </div>
              <script type="text/javascript">
                function cpm_start() {
                  document.getElementById('cpm_image').style.opacity = "1";
                }

                function cpm_stop() {
                  document.getElementById('cpm_image').style.opacity = "0";
                }
                cpm_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="">
                <papertitle>Composable Part-Based Manipulation</papertitle>
              </a>
              <br>
              <br>
              <strong>Weiyu Liu</strong>,
              <a href="https://jiayuanm.com/">Jiayuan Mao</a>,
              <a href="http://web.stanford.edu/~joycj/">Joy Hsu</a>,
              <a href="https://robot-learning.cs.utah.edu/thermans">Tucker Hermans</a>,
              <a href="https://animesh.garg.tech/">Animesh Garg</a>,
              <a href="https://jiajunwu.com/">Jiajun Wu</a>
              <br>
              <em>Conference on Robot Learning (CoRL)</em>, 2023
              <br>
              <a href="https://arxiv.org/abs/2405.05876">arxiv</a> /
              <a href="https://sites.google.com/view/part-based-manipulation">website</a> /
              <a href="data/cpm.bib">bibtex</a>
            </td>
          </tr>

          <tr onmouseout="structdiffusion_stop()" onmouseover="structdiffusion_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='structdiffusion_image'><video  width=100% height=100% muted autoplay loop>
                <source src="images/structdiffusion.mp4" type="video/mp4">
                Your browser does not support the video tag.
                </video></div>
                <img src='images/structdiffusion.jpg' width="160">
              </div>
              <script type="text/javascript">
                function structdiffusion_start() {
                  document.getElementById('structdiffusion_image').style.opacity = "1";
                }

                function structdiffusion_stop() {
                  document.getElementById('structdiffusion_image').style.opacity = "0";
                }
                structdiffusion_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/abs/2211.04604">
                <papertitle>StructDiffusion: Language-Guided Creation of Physically-Valid Structures using Unseen Objects</papertitle>
              </a>
              <br>
              <br>
              <strong>Weiyu Liu</strong>,
              <a href="https://yilundu.github.io/">Yilun Du</a>,
              <a href="https://robot-learning.cs.utah.edu/thermans">Tucker Hermans</a>,
              <a href="https://www.cc.gatech.edu/~chernova/">Sonia Chernova</a>,
              <a href="https://cpaxton.github.io/about/">Chris Paxton</a>
              <br>
              <em>Robotics: Science and Systems (RSS)</em>, 2023
              <br>
              <em>CoRL Workshop on Language and Robot Learning</em>, 2022
              <br>
              <a href="https://arxiv.org/abs/2211.04604">arxiv</a> /
              <a href="https://github.com/StructDiffusion/StructDiffusion">code & data</a> /
              <a href="https://structdiffusion.github.io/">website</a> /
              <a href="data/structdiffusion.bib">bibtex</a>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/survey.jpg" alt="survey_png" width="160" style="border-style: none">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://www.sciencedirect.com/science/article/abs/pii/S092188902200183X">
                <papertitle>A Survey of Semantic Reasoning Frameworks for Robotic Systems</papertitle>
              </a>
              <br>
              <br>
              <strong>Weiyu Liu<sup>1</sup></strong>,
              <a href="http://www.prism.gatech.edu/~adaruna3/">Angel Daruna<sup>1</sup></a>,
              <a href="https://maithili.github.io/">Maithili Patel<sup>2</sup></a>,
              <a href="https://kartikvrama.github.io/">Kartik Ramachandruni<sup>2</sup></a>,
              <a href="https://www.cc.gatech.edu/~chernova/">Sonia Chernova</a>
              <br>
              <em>Robotics and Autonomous Systems</em>, 2023
              <br>
              <a href="https://www.sciencedirect.com/science/article/abs/pii/S092188902200183X">paper</a> /
              <a href="data/LiuSurvey2023.bib">bibtex</a>
            </td>
          </tr>

          <tr onmouseout="eRD_stop()" onmouseover="eRD_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='eRD_image'><video  width=100% height=100% muted autoplay loop>
                <source src="images/eRD.mp4" type="video/mp4">
                Your browser does not support the video tag.
                </video></div>
                <img src='images/eRD.jpg' width="160">
              </div>
              <script type="text/javascript">
                function eRD_start() {
                  document.getElementById('eRD_image').style.opacity = "1";
                }

                function eRD_stop() {
                  document.getElementById('eRD_image').style.opacity = "0";
                }
                eRD_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/abs/2305.10857">
                <papertitle>Latent Space Planning for Multi-Object Manipulation with Environment-Aware Relational Classifiers</papertitle>
              </a>
              <br>
              <br>
              <a href="https://robot-learning.cs.utah.edu/yixuanh">Yixuan Huang</a>,
              <a href="https://nicholscrawford.github.io/">Nichols Crawford Taylor</a>,
              <a href="https://adamconkey.github.io/">Adam Conkey</a>,
              <strong>Weiyu Liu</strong>,
              <a href="https://robot-learning.cs.utah.edu/thermans">Tucker Hermans</a>,
              <br>
              <em>Under Review</em>, 2023
              <br>
              <a href="https://arxiv.org/abs/2305.10857">arxiv</a> /
              <a href="https://sites.google.com/view/erelationaldynamics">website</a> /
              <a href="data/erd.bib">bibtex</a>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/grasp_gpt.jpg" alt="grasp_gpt" width="160" style="border-style: none">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/abs/2307.13204">
                <papertitle>GraspGPT: Leveraging Semantic Knowledge from a Large Language Model for Task-Oriented Grasping</papertitle>
              </a>
              <br>
              <br>
              <a href="https://mkt1412.github.io/">Chao Tang</a>,
              Dehao Huang
              Wenqi Ge,
              <strong>Weiyu Liu</strong>,
              <a href="https://webdocs.cs.ualberta.ca/~zhang/index.html">Hong Zhang</a>
              <br>
              <em>Under Review</em>, 2023
              <br>
              <a href="https://arxiv.org/abs/2307.13204">arxiv</a> /
              <a href="https://github.com/mkt1412/GraspGPT_public">code & data</a> /
              <a href="https://sites.google.com/view/graspgpt/">website</a> /
              <a href="data/graspgpt.bib">bibtex</a>
            </td>
          </tr>

          <tr onmouseout="structformer_stop()" onmouseover="structformer_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='structformer_image'><video  width=100% height=100% muted autoplay loop>
                <source src="images/structformer.mp4" type="video/mp4">
                Your browser does not support the video tag.
                </video></div>
                <img src='images/structformer.jpg' width="160">
              </div>
              <script type="text/javascript">
                function structformer_start() {
                  document.getElementById('structformer_image').style.opacity = "1";
                }

                function structformer_stop() {
                  document.getElementById('structformer_image').style.opacity = "0";
                }
                structformer_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/abs/2110.10189">
                <papertitle>StructFormer: Learning Spatial Structure for Language-Guided Semantic Rearrangement of Novel Objects</papertitle>
              </a>
              <br>
              <br>
              <strong>Weiyu Liu</strong>,
              <a href="https://cpaxton.github.io/about/">Chris Paxton</a>,
              <a href="https://robot-learning.cs.utah.edu/thermans">Tucker Hermans</a>,
              <a href="https://homes.cs.washington.edu/~fox/">Dieter Fox</a>
              <br>
              <em>International Conference on Robotics and Automation (ICRA)</em>, 2022
              <br>
              <a href="https://arxiv.org/abs/2110.10189">arxiv</a> /
              <a href="https://github.com/wliu88/StructFormer">code & data</a> /
              <a href="https://sites.google.com/view/structformer">website</a> /
              <a href="https://drive.google.com/file/d/1LPGDk1ghZ_Zjxcx69-9GQOY_En0N3ZSD/view">talk</a> /
              <a href="data/LiuICRA2022.bib">bibtex</a>
            </td>
          </tr>

          <tr onmouseout="link_stop()" onmouseover="link_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='link_image'><video  width=100% height=100% muted autoplay loop>
                <source src="images/link.mp4" type="video/mp4">
                Your browser does not support the video tag.
                </video></div>
                <img src='images/link.jpg' width="160">
              </div>
              <script type="text/javascript">
                function link_start() {
                  document.getElementById('link_image').style.opacity = "1";
                }

                function link_stop() {
                  document.getElementById('link_image').style.opacity = "0";
                }
                link_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="http://www.roboticsproceedings.org/rss17/p035.html">
                <papertitle>Learning Instance-Level N-Ary Semantic Knowledge At Scale For Robots Operating in Everyday Environments
</papertitle>
              </a>
              <br>
              <br>
              <strong>Weiyu Liu</strong>,
              <a href="https://scholar.google.com/citations?user=uUTLG2IAAAAJ&hl=en">Dhruva Bansal</a>,
              <a href="http://www.prism.gatech.edu/~adaruna3/">Angel Daruna</a>,
              <a href="https://www.cc.gatech.edu/~chernova/">Sonia Chernova</a>
              <br>
              <em>Robotics: Science and Systems (RSS)</em>, 2021
              <br>
              <a href="http://www.roboticsproceedings.org/rss17/p035.html">paper</a> /
              <a href="https://github.com/wliu88/LINK">code & data</a> /
              <a href="https://youtu.be/uFxXQxOuTlo">talk</a> /
              <a href="data/LiuRSS2021.bib">bibtex</a>
            </td>
          </tr>

          <tr onmouseout="kg_task_stop()" onmouseover="kg_task_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='kg_task_image'><video  width=100% height=100% muted autoplay loop>
                <source src="images/kg_task.mp4" type="video/mp4">
                Your browser does not support the video tag.
                </video></div>
                <img src='images/kg_task.jpg' width="160">
              </div>
              <script type="text/javascript">
                function kg_task_start() {
                  document.getElementById('kg_task_image').style.opacity = "1";
                }

                function kg_task_stop() {
                  document.getElementById('kg_task_image').style.opacity = "0";
                }
                kg_task_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/abs/2105.04484">
                <papertitle>Towards Robust One-shot Task Execution using Knowledge Graph Embeddings</papertitle>
              </a>
              <br>
              <br>
              <a href="http://www.prism.gatech.edu/~adaruna3/">Angel Daruna</a>,
              <a href="https://sites.google.com/site/lvnair93/">Lakshmi Nair</a>,
              <strong>Weiyu Liu</strong>,
              <a href="https://www.cc.gatech.edu/~chernova/">Sonia Chernova</a>
              <br>
              <em>International Conference on Robotics and Automation (ICRA)</em>, 2021
              <br>
              <a href="https://arxiv.org/abs/2105.04484">arxiv</a> /
              <a href="data/DarunaICRA2021.bib">bibtex</a>
            </td>
          </tr>

          <tr onmouseout="affkpnet_stop()" onmouseover="affkpnet_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='affkpnet_image'><video  width=100% height=100% muted autoplay loop>
                <source src="images/affkpnet.mp4" type="video/mp4">
                Your browser does not support the video tag.
                </video></div>
                <img src='images/affkpnet.jpg' width="160">
              </div>
              <script type="text/javascript">
                function affkpnet_start() {
                  document.getElementById('affkpnet_image').style.opacity = "1";
                }

                function affkpnet_stop() {
                  document.getElementById('affkpnet_image').style.opacity = "0";
                }
                affkpnet_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://ieeexplore.ieee.org/abstract/document/9364360">
                <papertitle>An Affordance Keypoint Detection Network for Robot Manipulation</papertitle>
              </a>
              <br>
              <br>
              <a href="https://scholar.google.com/citations?user=qy644T4AAAAJ&hl=en">Ruinian Xu</a>,
              <a href="https://fujenchu.github.io/">Fu-Jen Chu</a>,
              <a href="https://scholar.google.com/citations?user=hXGhWsUAAAAJ&hl=zh-CN">Chao Tang</a>,
              <strong>Weiyu Liu</strong>,
              <a href="https://pvela.gatech.edu/">Patricio Vela</a>
              <br>
              <em>IEEE Robotics and Automation Letters (RA-L)</em>, 2021
              <br>
              <a href="https://ieeexplore.ieee.org/abstract/document/9364360">paper</a> /
              <a href="https://github.com/ivalab/AffKpNet">code & data</a> /
              <a href="data/XuRAL2021.bib">bibtex</a>
            </td>
          </tr>

          <tr onmouseout="kbgrasp_stop()" onmouseover="kbgrasp_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='kbgrasp_image'><video  width=100% height=100% muted autoplay loop>
                <source src="images/kbgrasp.mp4" type="video/mp4">
                Your browser does not support the video tag.
                </video></div>
                <img src='images/kbgrasp.jpg' width="161">
              </div>
              <script type="text/javascript">
                function kbgrasp_start() {
                  document.getElementById('kbgrasp_image').style.opacity = "1";
                }

                function kbgrasp_stop() {
                  document.getElementById('kbgrasp_image').style.opacity = "0";
                }
                kbgrasp_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/abs/2011.06431">
                <papertitle>Same Object, Different Grasps: Data and Semantic Knowledge for Task-Oriented Grasping</papertitle>
              </a>
              <br>
              <br>
              <a href="http://adithyamurali.com/">Adithya Murali</a>,
              <strong>Weiyu Liu</strong>,
              <a href="http://kennethmarino.com/">Kenneth Marino</a>,
              <a href="https://www.cc.gatech.edu/~chernova/">Sonia Chernova</a>,
              <a href="http://www.cs.cmu.edu/~abhinavg/">Abhinav Gupta</a>
              <br>
              <em>Conference on Robot Learning (CoRL)</em>, 2020
              <br>
              <a href="https://arxiv.org/abs/2011.06431">arxiv</a> /
              <a href="https://github.com/adithyamurali/TaskGrasp">code & data</a> /
              <a href="https://youtu.be/ByHVc-sPmd8">video</a> /
              <a href="https://youtu.be/eV-KyT6OK14">talk</a> /
              <a href="https://sites.google.com/view/taskgrasp">project page</a> / 
              <a href="data/MuraliCoRL2020.bib">bibtex</a>
            </td>
          </tr>

          <tr onmouseout="cage_stop()" onmouseover="cage_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='cage_image'><video  width=100% height=100% muted autoplay loop>
                <source src="images/cage.mp4" type="video/mp4">
                Your browser does not support the video tag.
                </video></div>
                <img src='images/cage.jpg' width="160">
              </div>
              <script type="text/javascript">
                function cage_start() {
                  document.getElementById('cage_image').style.opacity = "1";
                }

                function cage_stop() {
                  document.getElementById('cage_image').style.opacity = "0";
                }
                cage_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/abs/1909.11142">
                <papertitle>CAGE: Context-Aware Grasping Engine</papertitle>
              </a>
              <br>
              <br>
              <strong>Weiyu Liu</strong>,
              <a href="http://www.prism.gatech.edu/~adaruna3/">Angel Daruna</a>,
              <a href="https://www.cc.gatech.edu/~chernova/">Sonia Chernova</a>
              <br>
              <em>International Conference on Robotics and Automation (ICRA)</em>, 2020
              <br>
              <a href="https://arxiv.org/abs/1909.11142">arxiv</a> /
              <a href="https://github.com/wliu88/rail_semantic_grasping">code & data</a> /
              <a href="https://youtu.be/EnHUHQv8hr0">video</a> /
              <a href="https://icra.cc.gatech.edu/robots-gain-ability-to-master-object-manipulation-with-context-aware-technique/">press</a> /
              <a href="data/LiuICRA2020.bib">bibtex</a>
              <!--<a href="data/B3DO_ICCV_2011.bib">bibtex</a> /-->
              <!--<a href="https://drive.google.com/file/d/1qf4-U5RhSw12O7gzQwW66SMQhs2FWYDW/view?usp=sharing">"smoothing" code</a>-->
              <!--<p>We present a large RGB-D dataset of indoor scenes and investigate ways to improve object detection using depth information.</p>-->
            </td>
          </tr>

          <tr onmouseout="apr_stop()" onmouseover="apr_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='apr_image'><video  width=100% height=100% muted autoplay loop>
                <source src="images/apr.mp4" type="video/mp4">
                Your browser does not support the video tag.
                </video></div>
                <img src='images/apr.jpg' width="160">
              </div>
              <script type="text/javascript">
                function apr_start() {
                  document.getElementById('apr_image').style.opacity = "1";
                }

                function apr_stop() {
                  document.getElementById('apr_image').style.opacity = "0";
                }
                apr_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/abs/1905.10799">
                <papertitle>Path Ranking with Attention to Type Hierarchies</papertitle>
              </a>
              <br>
              <br>
              <strong>Weiyu Liu</strong>,
              <a href="http://www.prism.gatech.edu/~adaruna3/">Angel Daruna</a>,
              <a href="https://www.cc.gatech.edu/~zk15/">Zsolt Kira</a>,
              <a href="https://www.cc.gatech.edu/~chernova/">Sonia Chernova</a>
              <br>
              <em>Conference on Artificial Intelligence (AAAI)</em>, 2020 &nbsp <font color="red"><strong>(Oral Presentation)</strong></font>
              <br>
              <a href="https://arxiv.org/abs/1905.10799">arxiv</a> /
              <a href="https://github.com/wliu88/AttentivePathRanking">code</a> /
              <a href="data/LiuAAAI2020.bib">bibtex</a>
              <!--<a href="data/B3DO_ICCV_2011.bib">bibtex</a> /-->
              <!--<a href="https://drive.google.com/file/d/1qf4-U5RhSw12O7gzQwW66SMQhs2FWYDW/view?usp=sharing">"smoothing" code</a>-->
              <!--<p>We present a large RGB-D dataset of indoor scenes and investigate ways to improve object detection using depth information.</p>-->
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/recovery.png" alt="b3do" width="160" style="border-style: none">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="http://www.banerjs.com/pdf/banerjs_isrr2019.pdf">
                <papertitle>Taking Recoveries to Task: Recovery-Driven Development for Recipe-based Robot Tasks</papertitle>
              </a>
              <br>
              <br>
              <a href="http://www.banerjs.com/">Siddhartha Banerjee*</a>,
              <a href="http://www.prism.gatech.edu/~adaruna3/">Angel Daruna*</a>,
              <a href="https://scholar.google.com/citations?user=DJHyEHoAAAAJ&hl=en">David Kent*</a>,
              <strong>Weiyu Liu*</strong>,
              <a href="https://www.cc.gatech.edu/~jballoch6/">Jonathan Balloch</a>,
              <a href="https://abhinav-j.com/">Abhinav Jain</a>,
              <a href="https://scholar.google.com/citations?user=vHqNiLkAAAAJ&hl=en">Akshay Krishnan</a>,
              <a href="https://scholar.google.com/citations?user=0dQzZH8AAAAJ&hl=en">Muhammad Asif Rana</a>,
              <a href="https://harishravichandar.com/">Harish Ravichandar</a>,
              <a href="https://www.linkedin.com/in/binit-shah/">Binit Shah</a>,
              <a href="https://scholar.google.com/citations?user=CjDwqvsAAAAJ&hl=en">Nithin Shrivatsav</a>,
              <a href="https://www.cc.gatech.edu/~chernova/">Sonia Chernova</a>
              <br>
              <em>International Symposium on Robotics Research (ISRR)</em>, 2019
              <br>
              <a href="http://www.banerjs.com/pdf/banerjs_isrr2019.pdf">paper</a> /
              <a href="https://github.com/GT-RAIL/derail-fetchit-public">code</a> /
              <a href="data/BanerjeeISRR2019.bib">bibtex</a>
              <!--<a href="data/B3DO_ICCV_2011.bib">bibtex</a> /-->
              <!--<a href="https://drive.google.com/file/d/1qf4-U5RhSw12O7gzQwW66SMQhs2FWYDW/view?usp=sharing">"smoothing" code</a>-->
              <!--<p>We present a large RGB-D dataset of indoor scenes and investigate ways to improve object detection using depth information.</p>-->
            </td>
          </tr>

          <tr onmouseout="robocse_stop()" onmouseover="robocse_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='robocse_image'><video  width=100% height=100% muted autoplay loop>
                <source src="images/robocse_small.mp4" type="video/mp4">
                Your browser does not support the video tag.
                </video></div>
                <img src='images/robocse_small.jpg' width="160">
              </div>
              <script type="text/javascript">
                function robocse_start() {
                  document.getElementById('robocse_image').style.opacity = "1";
                }

                function robocse_stop() {
                  document.getElementById('robocse_image').style.opacity = "0";
                }
                robocse_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/abs/1903.00412">
                <papertitle>RoboCSE: Robot Common Sense Embedding</papertitle>
              </a>
              <br>
              <br>
              <a href="http://www.prism.gatech.edu/~adaruna3/">Angel Daruna</a>,
              <strong>Weiyu Liu</strong>,
              <a href="https://www.cc.gatech.edu/~zk15/">Zsolt Kira</a>,
              <a href="https://www.cc.gatech.edu/~chernova/">Sonia Chernova</a>
              <br>
              <em>International Conference on Robotics and Automation (ICRA)</em>, 2019
              <br>
              <a href="https://arxiv.org/abs/1903.00412">arxiv</a> /
              <a href="https://github.com/adaruna3/RoboCSE">code & data</a> /
              <a href="https://www.youtube.com/watch?v=ynHwNotCkDA">video</a> /
              <a href="data/DarunaICRA2019.bib">bibtex</a>
            </td>
          </tr>

          <tr onmouseout="blimp_stop()" onmouseover="blimp_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='blimp_image'><video  width=100% height=100% muted autoplay loop>
                <source src="images/blimp.mp4" type="video/mp4">
                Your browser does not support the video tag.
                </video></div>
                <img src='images/blimp.jpg' width="160">
              </div>
              <script type="text/javascript">
                function blimp_start() {
                  document.getElementById('blimp_image').style.opacity = "1";
                }

                function blimp_stop() {
                  document.getElementById('blimp_image').style.opacity = "0";
                }
                blimp_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://link.springer.com/article/10.1631/FITEE.1800587">
                <papertitle>Autonomous flying blimp interaction with human in an indoor space</papertitle>
              </a>
              <br>
              <br>
              <a href="https://ningshiyao.com/">Ningshi Yao</a>,
              <a href="https://www.taoqiuyang.com/">Qiuyang Tao</a>,
              <strong>Weiyu Liu</strong>,
              <a href="http://itszhen.com/">Zhen Liu</a>,
              Ye Tian,
              Peiyu Wang,
              Timothy Li,
              <a href="https://fumin.ece.gatech.edu/">Fumin Zhang</a>,
              <br>
              <em>Frontiers of Information Technology & Electronic Engineering</em>, 2019
              <br>
              <a href="https://link.springer.com/article/10.1631/FITEE.1800587">paper</a> /
              <a href="data/YaoFrontiers2019.bib">bibtex</a>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/sirok_big.png" alt="b3do" width="160" style="border-style: none">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://www.aaai.org/ocs/index.php/SSS/SSS18/paper/view/17517">
                <papertitle>SiRoK: Situated Robot Knowledge - Understanding the Balance Between Situated Knowledge and Variability</papertitle>
              </a>
              <br>
              <br>
              <a href="https://www.cc.gatech.edu/~chernova/">Sonia Chernova</a>,
              <a href="https://diligentrobots.com/vivian-chu">Vivian Chu</a>,
              <a href="http://www.prism.gatech.edu/~adaruna3/">Angel Daruna</a>,
              Haley Garrison,
              <a href="https://meerahahn.github.io/">Meera Hahn</a>,
              Priyanka Khante,
              <strong>Weiyu Liu</strong>,
              <a href="http://www.ece.utexas.edu/people/faculty/andrea-thomaz">Andrea Thomaz</a>,
              <br>
              <em>AAAI Spring Symposium Series (AAAI-SSS)</em>, 2018
              <br>
              <a href="https://www.aaai.org/ocs/index.php/SSS/SSS18/paper/view/17517">paper</a> /
              <a href="data/ChernovaAAAISSS2018.bib">bibtex</a>
            </td>
          </tr>

          <tr onmouseout="sbr_stop()" onmouseover="sbr_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='sbr_image'><video  width=100% height=100% muted autoplay loop>
                <source src="images/sbr.mp4" type="video/mp4">
                Your browser does not support the video tag.
                </video></div>
                <img src='images/sbr.jpg' width="160">
              </div>
              <script type="text/javascript">
                function sbr_start() {
                  document.getElementById('sbr_image').style.opacity = "1";
                }

                function sbr_stop() {
                  document.getElementById('sbr_image').style.opacity = "0";
                }
                sbr_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://link.springer.com/chapter/10.1007/978-3-030-28619-4_29">
                <papertitle>Situated Bayesian Reasoning Framework for Robots Operating in Diverse Everyday Environments</papertitle>
              </a>
              <br>
              <br>
              <a href="https://www.cc.gatech.edu/~chernova/">Sonia Chernova</a>,
              <a href="https://diligentrobots.com/vivian-chu">Vivian Chu</a>,
              <a href="http://www.prism.gatech.edu/~adaruna3/">Angel Daruna</a>,
              Haley Garrison,
              <a href="https://meerahahn.github.io/">Meera Hahn</a>,
              Priyanka Khante,
              <strong>Weiyu Liu</strong>,
              <a href="http://www.ece.utexas.edu/people/faculty/andrea-thomaz">Andrea Thomaz</a>,
              <br>
              <em>International Symposium on Robotics Research (ISRR)</em>, 2017
              <br>
              <a href="https://link.springer.com/chapter/10.1007/978-3-030-28619-4_29">paper</a> /
              <a href="data/ChernovaISRR2017.bib">bibtex</a>
            </td>
          </tr>

        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:0px">
              <br>
              <p style="text-align:right;font-size:small;">
                Website source from <a href="https://jonbarron.info/">Jon Barron</a>
              </p>
            </td>
          </tr>
        </tbody></table>

      </td>
    </tr>
  </table>
</body>

</html>
